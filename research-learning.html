<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width, initial-scale=1" name="viewport"/>
<title>Professor Fei Chen — Distributed learning</title>
<meta content="Academic personal webpage." name="description"/>
<link href="assets/style.css" rel="stylesheet"/>
</head>
<body>
<a class="skip" href="#main">Skip to content</a>
<div class="wrap">
<div class="layout">
<aside aria-label="Site navigation" class="sidebar">
<div class="brand">
<p class="name">Professor Fei Chen</p>
<div class="title">Principal Investigator, LICS</div>
<div class="meta"><a href="https://aien.nankai.edu.cn/" rel="noopener" target="_blank">College of AI</a>, <a href="https://en.nankai.edu.cn/" rel="noopener" target="_blank">Nankai University</a><br/>Tianjin, China</div><div class="social"><a href="https://scholar.google.com/citations?user=iNhrkt0AAAAJ&amp;hl=en" rel="noopener" target="_blank">Google Scholar</a><span class="sep">·</span><a href="https://orcid.org/0000-0002-8163-8238" rel="noopener" target="_blank">ORCID</a></div>
</div>
<nav class="menu">
<a class="" href="index.html">Home</a>
<a class="" href="contact.html">Contact</a>
<a class="" href="bio.html">Biography</a>
<div class="section">Research</div>
<a class="" href="group.html">Group (LICS)</a>
<a class="" href="openings.html">Openings</a>
<a class="" href="books.html">Books</a>
<a class="" href="publications.html">Publications</a>
<div class="section">Teaching</div>
<a class="" href="teaching.html">Courses</a>
</nav>
</aside>
<main class="content" id="main">
<img alt="LICS banner" class="banner" src="assets/banner.jpg"/>
<h1>Distributed learning</h1><p class="muted"><a href="index.html#research">← Back to Research interests</a></p>
<p class="muted">Our learning direction focuses on reinforcement learning (RL) and meta-learning for decision-making and adaptive control, with an emphasis on networked and multi-agent systems.</p>
<img alt="Learning (reinforcement &amp; meta learning) header illustration" class="hero" src="assets/research/learning.jpg"/>
<h2>What this field is about</h2>
<ul><li>Reinforcement learning: learn a policy π(a|s) by interacting with an environment and maximizing long-term return.</li><li>RL for control: data-driven controllers for tracking, stabilization, and planning under uncertainty and constraints.</li><li>Multi-agent / networked RL: coordination and communication among agents (e.g., formation, coverage, and distributed decision-making).</li><li>Meta-learning: learn a good initialization or update rule so a policy/controller adapts to a new task with only a few samples or gradient steps.</li><li>Key themes: safety &amp; stability, sample efficiency, and generalization across tasks and operating conditions.</li></ul>
<h2>Illustrations</h2>
<div class="grid grid2">
<div class="card">
<img alt="Animated illustration of reinforcement learning loop and learning curve" src="assets/research-pages/learning_federated.gif"/>
<div class="pad">
<h3>Reinforcement learning (RL)</h3>
<p>Agent–environment interaction, policy improvement, and a typical learning curve (episode return).</p>
</div>
</div>
<div class="card">
<img alt="Illustration of meta-learning (MAML-style) for fast adaptation" src="assets/research-pages/learning_message_passing.jpg"/>
<div class="pad">
<h3>Meta-learning</h3>
<p>Meta-training across tasks to obtain an initialization that adapts quickly to a new task (few-shot).</p>
</div>
</div>
</div>
<h2>Typical applications</h2>
<ul><li>Learning-based control for robotics and autonomous vehicles (navigation, tracking, manipulation).</li><li>Adaptive decision-making in networked systems (smart grids, smart manufacturing, traffic and mobility).</li><li>Multi-agent coordination: formation, coverage, and task allocation with learned policies.</li><li>Rapid adaptation to changing dynamics or environments via meta-learning (few-shot personalization).</li></ul>
<h2>Related reading</h2><ul class="reading"><li><a href="http://incompleteideas.net/book/the-book-2nd.html">Sutton &amp; Barto. Reinforcement Learning: An Introduction (2nd ed.).</a></li><li><a href="https://arxiv.org/abs/1703.03400">Finn, Abbeel &amp; Levine. Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks (MAML), 2017.</a></li><li><a href="https://arxiv.org/abs/1707.06347">Schulman et al. Proximal Policy Optimization Algorithms (PPO), 2017.</a></li><li><a href="https://arxiv.org/abs/1801.01290">Haarnoja et al. Soft Actor-Critic: Off-Policy Maximum Entropy Deep Reinforcement Learning, 2018.</a></li><li><a href="https://arxiv.org/abs/1611.02779">Duan et al. RL^2: Fast Reinforcement Learning via Slow Reinforcement Learning, 2016.</a></li><li><a href="https://scholar.google.com/scholar?q=Multi-ASV%20coordinated%20tracking%20model-reference%20reinforcement%20learning%20control%20Fei%20Chen">Hu Wenbo; Fei Chen*; et al. Multi-ASV coordinated tracking via model-reference reinforcement learning control (IEEE TCYB, 2023).</a></li><li><a href="https://www.emerald.com/ftsys/article-abstract/6/4/339/1332408/On-the-Control-of-Multi-Agent-Systems-A-Survey">Fei Chen; Wei Ren. On the Control of Multi-Agent Systems: A Survey (FnT Systems and Control, 2019).</a></li><li><a href="https://scholar.google.com/scholar?q=multi-agent%20reinforcement%20learning%20survey">Multi-agent reinforcement learning survey (select one as a starting point).</a></li></ul><p class="muted">Interested in joining? See <a href="openings.html">Openings</a>.</p>
<div class="footer">© 2026 Professor Fei Chen · Laboratory for Information and Control Systems (LICS)</div>
</main>
</div>
</div>
</body>
</html>
